{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b67cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d244ba0a",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e4e3b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"../datasets/CCBIS-DDSM/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c9c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATASET_DIR, \"train.csv\"))\n",
    "validation_df = pd.read_csv(os.path.join(DATASET_DIR, \"validation.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(DATASET_DIR, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85465670",
   "metadata": {},
   "source": [
    "## Patch Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f57e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "def file_exists(path):\n",
    "    return os.path.isfile(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4880184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(bbox_a, bbox_b):\n",
    "    \"\"\"\n",
    "    Checks for overlap between two bounding boxes\n",
    "    Boxes must be in x, y, w, h format\n",
    "    \"\"\"\n",
    "    x1 = max(bbox_a[0], bbox_b[0])\n",
    "    x2 = min(bbox_a[0] + bbox_a[2], bbox_b[0] + bbox_b[2])\n",
    "    y1 = max(bbox_a[1], bbox_b[1])\n",
    "    y2 = min(bbox_a[1] + bbox_a[3], bbox_b[1] + bbox_b[3])\n",
    "    \n",
    "    area = max(0, x2-x1+1) * max(0, y2-y1+1)\n",
    "    return area\n",
    "\n",
    "def get_patch_location_random(bbox, image_shape):\n",
    "    \"\"\"\n",
    "    Gets the patch starting points for a lession in the image.\n",
    "    Puts the starting point at a random location such that the patch area selected is random inside the lession\n",
    "    \"\"\"\n",
    "    # Unpack bbox\n",
    "    x, y, w, h = bbox\n",
    "    \n",
    "    # There are two possibilities:\n",
    "    # 1. The lession is smaller than the patch size:\n",
    "    #      In this case, we will center the patch on the lession and then slightly move the patch with a random offset\n",
    "    # 2. The lession is bigger than the patch size:\n",
    "    #      In this case, we will just choose a randomly selected starting point for the patch inside the bounding box\n",
    "    \n",
    "    # Case 1\n",
    "    if(w <= PATCH_WIDTH):\n",
    "        patch_x = np.random.randint(x + (w/2) - (PATCH_WIDTH/2) - 10, x + (w/2) - (PATCH_WIDTH/2) + 10)\n",
    "    if(h <= PATCH_HEIGHT):\n",
    "        patch_y = np.random.randint(y + (h/2) - (PATCH_HEIGHT/2) - 10, y + (h/2) - (PATCH_HEIGHT/2) + 10)\n",
    "    \n",
    "    # Case 2\n",
    "    if(w > PATCH_WIDTH):\n",
    "        patch_x = np.random.randint(x - 10, x + w - PATCH_WIDTH + 10)\n",
    "    if(h > PATCH_WIDTH):\n",
    "        patch_y = np.random.randint(y - 10, y + h - PATCH_HEIGHT + 10)\n",
    "    \n",
    "    # Ensure they are all inside the image\n",
    "    if patch_x < 0: patch_x = 0\n",
    "    if patch_x + PATCH_WIDTH > image_shape[1]: patch_x = image_shape[1] - PATCH_WIDTH\n",
    "    if patch_y < 0: patch_y = 0\n",
    "    if patch_y + PATCH_HEIGHT > image_shape[0]: patch_y = image_shape[0] - PATCH_HEIGHT\n",
    "    \n",
    "    return int(patch_x), int(patch_y)\n",
    "\n",
    "def get_background_location(bboxes, image_shape):\n",
    "    \"\"\"\n",
    "    Get the patch starting points for the background patches in the image\n",
    "    Selects background from places where there are no lessions\n",
    "    \"\"\"\n",
    "    while(True):\n",
    "        # Get a random value for the background starting point\n",
    "        bg_x = np.random.randint(image_shape[1] - PATCH_WIDTH)\n",
    "        bg_y = np.random.randint(image_shape[0] - PATCH_HEIGHT)\n",
    "        \n",
    "        # Counter to ensure all bounding boxes don't collide with the background class\n",
    "        i = 0\n",
    "        for bbox in bboxes:\n",
    "            # Unpack values\n",
    "            x, y, w, h = bbox\n",
    "            # Check that the starting point is not inside any bounding box\n",
    "            if overlap(bbox, [bg_x, bg_y, PATCH_WIDTH, PATCH_HEIGHT]) == 0:\n",
    "                i = i+1\n",
    "        \n",
    "        # If i is the same as the number of boxes, it means the background doesn't collide with any bbox\n",
    "        # So we can use it.\n",
    "        if(i == len(bboxes)):\n",
    "            return int(bg_x), int(bg_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8b33643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lession_patches(bboxes, image):\n",
    "    patches = []\n",
    "    for bbox in bboxes:\n",
    "        for i in range(NUM_PATCHES):\n",
    "            # For each bounding box get the starting coordinates for the patch\n",
    "            x, y = get_patch_location_random(bbox, image.shape)\n",
    "            # Extract the lession patch\n",
    "            patches.append(image[y:y+PATCH_HEIGHT, x:x+PATCH_WIDTH])\n",
    "    return patches\n",
    "    \n",
    "def get_background_patches(bboxes, image):\n",
    "    backgrounds = []\n",
    "    # Get the same number of background patches as there are patches\n",
    "    for i in range(len(bboxes)):\n",
    "        for j in range(NUM_PATCHES):\n",
    "            patch = [0]\n",
    "            # Iterate over different backgrounds until we have one that has useful information (isn't just black)\n",
    "            while(np.amax(patch) == 0):\n",
    "                x, y = get_background_location(bboxes, image.shape)\n",
    "                patch = image[y:y+PATCH_HEIGHT, x:x+PATCH_WIDTH]\n",
    "            backgrounds.append(patch)\n",
    "    return backgrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b47a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_S10(df, target_folder):\n",
    "    j = 0\n",
    "    for image_name in tqdm(df[\"Image\"].unique()):\n",
    "        # Load the image and mask\n",
    "        if not file_exists(os.path.join(DATASET_DIR, image_name)):\n",
    "            print(\"[ERROR] {} does not exist!\".format(image_name))\n",
    "            continue\n",
    "        image = np.array(Image.open(os.path.join(DATASET_DIR, image_name)))\n",
    "\n",
    "        # Get all lessions related to a specific image\n",
    "        tmp_df = df[df[\"Image\"] == image_name]\n",
    "\n",
    "        # Extract bounding boxes information for each lession\n",
    "        bboxes = np.array(tmp_df.iloc[:, -4:].values)\n",
    "\n",
    "        # Get all lession patches\n",
    "        patches = get_lession_patches(bboxes, image)\n",
    "\n",
    "        # Get all background patches\n",
    "        backgrounds = get_background_patches(bboxes, image)\n",
    "\n",
    "        # Save images\n",
    "        for i in range(len(patches)):\n",
    "            file_path = target_folder + tmp_df.iloc[i//NUM_PATCHES][\"Abnormality_Type\"] + \"_\" + tmp_df.iloc[i//NUM_PATCHES][\"Pathology\"] + \"/\" + tmp_df.iloc[i//NUM_PATCHES][\"Patient_ID\"] + \"_\" + tmp_df.iloc[i//NUM_PATCHES][\"Left_Right_Breast\"] + \"_\" + tmp_df.iloc[i//NUM_PATCHES][\"Image_View\"] + \"_\" + str(i) + \".png\"\n",
    "            im = Image.fromarray(patches[i])\n",
    "            im.save(file_path)\n",
    "\n",
    "        for i in range(len(backgrounds)):\n",
    "            file_path = target_folder + \"background/\" + str(j) + \".png\"\n",
    "            j = j+1\n",
    "            im = Image.fromarray(backgrounds[i])\n",
    "            im.save(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc23629",
   "metadata": {},
   "source": [
    "## S10 Dataset Creation\n",
    "\n",
    "The S10 Dataset consists of a larger amount of small patches taken from the bounding box indicating where the lesion is. These patches are randomly sampled from around where the lession is, essentially augmentating the number of patches to train the model.\n",
    "\n",
    "We also create the S10-Big dataset, taking into consideration the average size of the bounding boxes found in the CCBIS-DDSM Dataset, and use a patch of 512x512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1f17f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_HEIGHT = 224\n",
    "PATCH_WIDTH = 224\n",
    "NUM_PATCHES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "003eb094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1938/1938 [08:17<00:00,  3.90it/s]\n"
     ]
    }
   ],
   "source": [
    "create_S10(train_df, \"../datasets/S10/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53251dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 548/548 [02:13<00:00,  4.09it/s]\n"
     ]
    }
   ],
   "source": [
    "create_S10(validation_df, \"../datasets/S10/validation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a391653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 632/632 [02:39<00:00,  3.97it/s]\n"
     ]
    }
   ],
   "source": [
    "create_S10(test_df, \"../datasets/S10/test/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef936039",
   "metadata": {},
   "source": [
    "## S10-Big Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff8d7b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_HEIGHT = 512\n",
    "PATCH_WIDTH = 512\n",
    "NUM_PATCHES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44960498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1938/1938 [26:44<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "create_S10(train_df, \"../datasets/S10-Big/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46863824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 548/548 [06:57<00:00,  1.31it/s]\n"
     ]
    }
   ],
   "source": [
    "create_S10(validation_df, \"../datasets/S10-Big/validation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "343d08e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 632/632 [08:19<00:00,  1.27it/s]\n"
     ]
    }
   ],
   "source": [
    "create_S10(test_df, \"../datasets/S10-Big/test/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
