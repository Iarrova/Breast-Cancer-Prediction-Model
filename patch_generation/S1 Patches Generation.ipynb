{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b67cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d244ba0a",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e4e3b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"../datasets/CCBIS-DDSM/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c9c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATASET_DIR, \"train.csv\"))\n",
    "validation_df = pd.read_csv(os.path.join(DATASET_DIR, \"validation.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(DATASET_DIR, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85465670",
   "metadata": {},
   "source": [
    "## Patch Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f57e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "def file_exists(path):\n",
    "    return os.path.isfile(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4880184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(bbox_a, bbox_b):\n",
    "    \"\"\"\n",
    "    Checks for overlap between two bounding boxes\n",
    "    Boxes must be in x, y, w, h format\n",
    "    \"\"\"\n",
    "    x1 = max(bbox_a[0], bbox_b[0])\n",
    "    x2 = min(bbox_a[0] + bbox_a[2], bbox_b[0] + bbox_b[2])\n",
    "    y1 = max(bbox_a[1], bbox_b[1])\n",
    "    y2 = min(bbox_a[1] + bbox_a[3], bbox_b[1] + bbox_b[3])\n",
    "    \n",
    "    area = max(0, x2-x1+1) * max(0, y2-y1+1)\n",
    "    return area\n",
    "\n",
    "def get_patch_location(bbox, image_shape):\n",
    "    \"\"\"\n",
    "    Gets the patch starting points for a lession in the image.\n",
    "    Puts the starting points so that the extracted patch is in the center of the lession.\n",
    "    \"\"\"\n",
    "    # Unpack bbox\n",
    "    x, y, w, h = bbox\n",
    "    \n",
    "    # Set the starting points for the patch\n",
    "    patch_x = x + (w/2) - (PATCH_WIDTH/2)\n",
    "    patch_y = y + (h/2) - (PATCH_HEIGHT/2)\n",
    "    \n",
    "    # Ensure they are all inside the image\n",
    "    if patch_x < 0: patch_x = 0\n",
    "    if patch_x + PATCH_WIDTH > image_shape[1]: patch_x = image_shape[1] - PATCH_WIDTH\n",
    "    if patch_y < 0: patch_y = 0\n",
    "    if patch_y + PATCH_HEIGHT > image_shape[0]: patch_y = image_shape[0] - PATCH_HEIGHT\n",
    "    \n",
    "    return int(patch_x), int(patch_y)\n",
    "\n",
    "def get_background_location(bboxes, image_shape):\n",
    "    \"\"\"\n",
    "    Get the patch starting points for the background patches in the image\n",
    "    Selects background from places where there are no lessions\n",
    "    \"\"\"\n",
    "    while(True):\n",
    "        # Get a random value for the background starting point\n",
    "        bg_x = np.random.randint(image_shape[1] - PATCH_WIDTH)\n",
    "        bg_y = np.random.randint(image_shape[0] - PATCH_HEIGHT)\n",
    "        \n",
    "        # Counter to ensure all bounding boxes don't collide with the background class\n",
    "        i = 0\n",
    "        for bbox in bboxes:\n",
    "            # Unpack values\n",
    "            x, y, w, h = bbox\n",
    "            # Check that the starting point is not inside any bounding box\n",
    "            if overlap(bbox, [bg_x, bg_y, PATCH_WIDTH, PATCH_HEIGHT]) == 0:\n",
    "                i = i+1\n",
    "        \n",
    "        # If i is the same as the number of boxes, it means the background doesn't collide with any bbox\n",
    "        # So we can use it.\n",
    "        if(i == len(bboxes)):\n",
    "            return int(bg_x), int(bg_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8b33643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lession_patches(bboxes, image):\n",
    "    patches = []\n",
    "    for bbox in bboxes:\n",
    "        # For each bounding box get the starting coordinates for the patch\n",
    "        x, y = get_patch_location(bbox, image.shape)\n",
    "        # Extract the lession patch\n",
    "        patches.append(image[y:y+PATCH_HEIGHT, x:x+PATCH_WIDTH])\n",
    "    return patches\n",
    "    \n",
    "def get_background_patches(bboxes, image):\n",
    "    backgrounds = []\n",
    "    # Get the same number of background patches as there are patches\n",
    "    for i in range(len(bboxes)):\n",
    "        patch = [0]\n",
    "        # Iterate over different backgrounds until we have one that has useful information (isn't just black)\n",
    "        while(np.amax(patch) == 0):\n",
    "            x, y = get_background_location(bboxes, image.shape)\n",
    "            patch = image[y:y+PATCH_HEIGHT, x:x+PATCH_WIDTH]\n",
    "        backgrounds.append(patch)\n",
    "    return backgrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b47a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_S1(df, target_folder):\n",
    "    j = 0\n",
    "    for image_name in tqdm(df[\"Image\"].unique()):\n",
    "        # Load the image and mask\n",
    "        if not file_exists(os.path.join(DATASET_DIR, image_name)):\n",
    "            print(\"[ERROR] {} does not exist!\".format(image_name))\n",
    "            continue\n",
    "        image = np.array(Image.open(os.path.join(DATASET_DIR, image_name)))\n",
    "\n",
    "        # Get all lessions related to a specific image\n",
    "        tmp_df = df[df[\"Image\"] == image_name]\n",
    "\n",
    "        # Extract bounding boxes information for each lession\n",
    "        bboxes = np.array(tmp_df.iloc[:, -4:].values)\n",
    "\n",
    "        # Get all lession patches\n",
    "        patches = get_lession_patches(bboxes, image)\n",
    "\n",
    "        # Get all background patches\n",
    "        backgrounds = get_background_patches(bboxes, image)\n",
    "\n",
    "        # Save images\n",
    "        for i in range(len(patches)):\n",
    "            file_path = target_folder + tmp_df.iloc[i][\"Abnormality_Type\"] + \"_\" + tmp_df.iloc[i][\"Pathology\"] + \"/\" + tmp_df.iloc[i][\"Patient_ID\"] + \"_\" + tmp_df.iloc[i][\"Left_Right_Breast\"] + \"_\" + tmp_df.iloc[i][\"Image_View\"] + \"_\" + str(i) + \".png\"\n",
    "            im = Image.fromarray(patches[i])\n",
    "            im.save(file_path)\n",
    "\n",
    "        for i in range(len(backgrounds)):\n",
    "            file_path = target_folder + \"background/\" + str(j) + \".png\"\n",
    "            j = j+1\n",
    "            im = Image.fromarray(backgrounds[i])\n",
    "            im.save(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc23629",
   "metadata": {},
   "source": [
    "## S1 Dataset Creation\n",
    "\n",
    "The S1 Dataset consists of small patches taken from the bounding box indicating where the lesion is.\n",
    "Patches are taken from a centered position.\n",
    "\n",
    "We also create the S1-Big dataset, taking into consideration the average size of the bounding boxes found in the CCBIS-DDSM Dataset, and use a patch of 512x512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1f17f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_HEIGHT = 224\n",
    "PATCH_WIDTH = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "003eb094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1938/1938 [04:16<00:00,  7.55it/s]\n"
     ]
    }
   ],
   "source": [
    "create_S1(train_df, \"../datasets/S1/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53251dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 548/548 [01:19<00:00,  6.93it/s]\n"
     ]
    }
   ],
   "source": [
    "create_S1(validation_df, \"../datasets/S1/validation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a391653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 632/632 [01:28<00:00,  7.14it/s]\n"
     ]
    }
   ],
   "source": [
    "create_S1(test_df, \"../datasets/S1/test/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef936039",
   "metadata": {},
   "source": [
    "## S1-Big Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff8d7b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_HEIGHT = 512\n",
    "PATCH_WIDTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44960498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1938/1938 [06:17<00:00,  5.14it/s]\n"
     ]
    }
   ],
   "source": [
    "create_S1(train_df, \"../datasets/S1-Big/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46863824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 548/548 [01:44<00:00,  5.22it/s]\n"
     ]
    }
   ],
   "source": [
    "create_S1(validation_df, \"../datasets/S1-Big/validation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "343d08e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 632/632 [02:01<00:00,  5.20it/s]\n"
     ]
    }
   ],
   "source": [
    "create_S1(test_df, \"../datasets/S1-Big/test/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
